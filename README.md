# text-generator.gpt
Text Generator is a Python project that uses the GPT-2 model from Hugging Face's Transformers library to generate meaningful text continuations based on user input. Users can input a sentence, which is then tokenized and processed by the GPT-2 model to produce a coherent continuation using techniques like beam search for improved quality.
